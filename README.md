# üåü Celestial - NASA Data Pipeline

Este projeto de Engenharia de Dados consiste na constru√ß√£o de uma infraestrutura de dados escal√°vel para coleta, processamento e modelagem anal√≠tica de eventos astron√¥micos e objetos pr√≥ximos √† Terra (NEOs). 
O projeto consolida dados das APIs **NeoWs**, **Fireball** e **CAD (JPL)** em um Data Warehouse estruturado.

As APIs da NASA fornecem dados incr√≠veis, mas eles v√™m em um formato "bagun√ßado" para an√°lise (JSON aninhado). Este projeto automatiza o trabalho de buscar esses dados todos os dias e transform√°-los em informa√ß√µes √∫teis, como:
- Asteroides: Quais est√£o passando perto da Terra hoje?
- B√≥lidos: Onde ca√≠ram meteoros brilhantes recentemente?
- Hist√≥rico: Como foi o movimento espacial nos √∫ltimos 6 meses?

---

## üèóÔ∏è Arquitetura do Pipeline

<img width="1609" height="872" alt="Image" src="https://github.com/juniorsilvacc/astrotrack-etl-dw/blob/master/arquitetura.png" />

## Para garantir que a informa√ß√£o seja confi√°vel, usamos o padr√£o de Medalh√£o:

- Bronze ü•â
  - Guardamos o dado exatamente como ele veio da NASA. Se precisarmos conferir algo no futuro, o original est√° l√°.

- Silver ü•à
  - Removemos o que n√£o serve, corrigimos formatos de data, calculamos o tamanho m√©dio dos asteroides e salvamos de forma organizada e r√°pida (Parquet).

- Gold ü•á
  - Organizamos os dados em tabelas especiais (Fatos e Dimens√µes) que facilitam a cria√ß√£o de gr√°ficos e relat√≥rios profissionais.

---

## üìÇ Estrutura do Projeto
```text
src/
‚îú‚îÄ‚îÄ shared/                 # Ferramentas e Infraestrutura Reutiliz√°vel
‚îÇ   ‚îú‚îÄ‚îÄ storage/            # Handlers para Local Files (IO) e Banco de Dados (DB)
‚îÇ   ‚îú‚îÄ‚îÄ drivers/            # Motores de conex√£o (SQLAlchemy/Postgres) e Request
‚îÇ   ‚îî‚îÄ‚îÄ integrations/       # Clientes de comunica√ß√£o com APIs NASA
‚îú‚îÄ‚îÄ bronze/                 # Scripts de Ingest√£o (Extract)
‚îú‚îÄ‚îÄ silver/                 # Scripts de Limpeza e Padroniza√ß√£o (Transform)
‚îú‚îÄ‚îÄ gold/                   # Modelagem SQL e L√≥gica Anal√≠tica
‚îÇ   ‚îî‚îÄ‚îÄ analytics/          # Queries SQL organizadas por dom√≠nio FCT(Fato) e DIM(Dimens√£o) (CAD, NeoWS, Fireball)
‚îî‚îÄ‚îÄ main.py                 # Ponto de entrada para execu√ß√£o manual
```

---

## üõ†Ô∏è Tecnologias Utilizadas
### Core
- **Orquestra√ß√£o:** Apache Airflow (TaskFlow API com processamento paralelo).
- **Linguagem:** Python 3.12 (Pandas para processamento, SQLAlchemy para persist√™ncia).
- **Banco de Dados:** PostgreSQL (Data Warehouse).
- **Infraestrutura:** Docker & Docker Compose (Isolamento de ambiente).
- **Armazenamento Colunar:** Apache Parquet.
  
### Bibliotecas Python
- **pandas:** Manipula√ß√£o e transforma√ß√£o de dados.
- **requests:** Requisi√ß√µes HTTP para a API.
- **SQLAlchemy:** ORM para intera√ß√£o com o banco de dados.
- **psycopg2:** Driver PostgreSQL.
- **python-dotenv:** Gerenciamento de vari√°veis de ambiente.

---

## ‚öôÔ∏è Detalhamento das Etapas de Transforma√ß√£o (Silver Layer)
O cora√ß√£o do projeto reside na camada Silver, onde os dados brutos e aninhados das APIs da NASA s√£o submetidos a um rigoroso processo de limpeza e normaliza√ß√£o.

### ‚òÑÔ∏è API Fireball (B√≥lidos)
Os dados de impactos de meteoros possuem coordenadas geogr√°ficas e componentes de velocidade vetorial.

- **Tratamento de Coordenadas:** Convers√£o de dire√ß√µes cardeais (N/S, E/W) em valores num√©ricos decimais para plotagem em mapas.

- **C√°lculo de Energia:** Padroniza√ß√£o das unidades de energia radiada (Joules) e impacto total estimado (kt).

- **Normaliza√ß√£o:** Extra√ß√£o de dados aninhados para uma estrutura tabular limpa.

### üõ∞Ô∏è API NeoWs (Asteroides)
A API de Objetos Pr√≥ximos √† Terra √© a mais complexa devido √† estrutura de datas e aproxima√ß√µes m√∫ltiplas.

- **Normaliza√ß√£o Recursiva:** Extra√ß√£o de asteroides listados por data dentro da chave `near_earth_objects`.

- **Deduplica√ß√£o Inteligente:** Remo√ß√£o de duplicatas baseada no `asteroide_id` e `data_aproximacao`.

- **C√°lculo de Di√¢metro:** Cria√ß√£o da m√©trica `diameter_avg_km` baseada na m√©dia entre o di√¢metro m√≠nimo e m√°ximo estimado pela NASA.

- **Convers√£o de Tipos:** Transforma√ß√£o de strings de velocidade (`km/h`) e dist√¢ncia (`km`) em tipos num√©ricos (`loat64`) para c√°lculos anal√≠ticos.

### üî≠ API CAD (JPL - Close Approach Data)
Focada em aproxima√ß√µes calculadas, requer filtros espec√≠ficos para evitar sobrecarga de dados.

- **Filtros de Data:**  Implementa√ß√£o de l√≥gica para capturar apenas aproxima√ß√µes em janelas temporais relevantes.

- **Velocidade Relativa:**  Separa√ß√£o e limpeza de dados de velocidade relativa em rela√ß√£o √† Terra.

- **Enriquecimento:**  Prepara√ß√£o dos dados para o Join na camada Gold com as caracter√≠sticas f√≠sicas dos asteroides vindas do NeoWs.

---

## üíé O Processo de Transforma√ß√£o (L√≥gica do C√≥digo)
Para garantir a qualidade, todas as transforma√ß√µes seguem este fluxo program√°tico:

1. **Leitura Colunar:** Carregamento eficiente dos arquivos JSON originais.
2. **Drop de Redund√¢ncias:** Remo√ß√£o de colunas irrelevantes (links internos da NASA, unidades de medida duplicadas como milhas/p√©s).
3. **Renomea√ß√£o T√©cnica:** Tradu√ß√£o e padroniza√ß√£o dos nomes das colunas para o portugu√™s e para o padr√£o snake_case.
4. **Persist√™ncia Colunar:** Salvamento em formato Parquet com compress√£o snappy, reduzindo o espa√ßo em disco em at√© 70% comparado ao CSV/JSON.
5. **Upsert no Database:** Utiliza√ß√£o da fun√ß√£o customizada save_dataframe (no db_handler.py) que gerencia a cria√ß√£o autom√°tica de tabelas e a atualiza√ß√£o dos dados no PostgreSQL.

---

## üìä Modelagem Dimensional (GOLD)
O Data Warehouse segue o modelo Star Schema:

- Fatos: `fct_impactos (Fireball)`, `fct_aproximacoes (CAD)`, `fct_monitoramento_neows (NeoWS)`.
- Dimens√µes: `dim_localizacao (Fireball)`, `dim_tempo (Fireball)`, `dim_objeto_espacial (CAD)`, `dim_asteroide_perfil_neows (NeoWS)`.

---

## üîÑ Orquestra√ß√£o (Airflow)
A pipeline √© inteligente e resiliente:
1. **Paralelismo**: As ingest√µes de NeoWs, Fireball e CAD ocorrem simultaneamente para otimizar o tempo.
2. **Carga Hist√≥rica Autom√°tica**: O sistema detecta a aus√™ncia de dados hist√≥ricos (Backfill) e provisiona o banco automaticamente na primeira execu√ß√£o.
3. **Integridade**: A camada Gold possui depend√™ncia estrita do sucesso de todas as camadas Silver anteriores.

---

## ‚õìÔ∏è Fluxo da DAG no Airflow
**Arquivo:** [astrotrack_dag.py](https://github.com/juniorsilvacc/astrotrack-etl-dw/blob/master/dags/astrotrack_dag.py)

### Configura√ß√£o da DAG
```bash
@dag(
  dag_id='astrotrack_etl',
  default_args={
    'owner': 'airflow',
    'depends_on_past': False,
    'retries': 2,
    'retry_delay': timedelta(minutes=5)
  },
  description='Pipeline ETL: NeoWS, Fireball e CAD',
  schedule='0 4 * * *', # Executa √†s 04:00 AM (Todos os dias)
  start_date=datetime(2026, 2, 1),
  catchup=False,
  tags=['nasa', 'cad', 'neows', 'fireball', 'etl']
) 
```

### Tasks Defininas
```bash
@task
  def process_fireball():
    run_extract_fireball()
    run_transform_fireball()
      
  @task
  def process_neows():
    run_extract_neows()
    run_neows_historical()
    run_neows_daily()

  @task
  def process_cad():
    run_extract_cad()
    run_transform_cad()

  @task
  def build_gold():
    build_gold_layer()
  
  [process_fireball(), process_neows(), process_cad()] >> build_gold()
```

### Por que usar Parquet entre transform e load?
- Formato bin√°rio eficiente
- Preserva tipos de dados (datetime, float, etc.)
- Evita problemas com serializa√ß√£o do Airflow

---

## üöÄ Instala√ß√£o e Configura√ß√£o
### 1Ô∏è‚É£ Clone o reposit√≥rio:
```bash
# 1. Clone o reposit√≥rio:
git clone [https://github.com/seu-usuario/astrotrack-etl.git](https://github.com/seu-usuario/astrotrack-etl.git)
```

### 2Ô∏è‚É£ Obtenha sua API Key NeoWS - NASA
1. Acesse [APIs Nasa](https://api.nasa.gov/) 
2. Crie uma conta gratuita
3. Gere sua API Key e recebe por email
4. Guarde sua chave para o pr√≥ximo passo
   
### 3Ô∏è‚É£Configure as vari√°veis no .env
```bash
DB_HOST=postgres
DB_NAME=airflow
DB_USER=airflow
DB_PASSWORD=airflow
DB_PORT=5432

AIRFLOW_UID=501

# APIs Integrations
API_FIREBALL_NASA=https://ssd-api.jpl.nasa.gov/
API_CAD_NASA=https://ssd-api.jpl.nasa.gov/
API_NEOWS_NASA=https://api.nasa.gov/neo/rest/v1

# API KEY (Inserir a chave da api) 
API_KEY_NEOWS=
```

### 4Ô∏è‚É£ Inicialize o Ambiente Airflow
```bash
# Crie a estrutura de pastas necess√°ria
mkdir -p ./dags ./logs ./plugins ./config ./data ./src ./notebooks

# Configure as permiss√µes (Linux/Mac)
echo -e "AIRFLOW_UID=$(id -u)" > .env
```

### 5Ô∏è‚É£ Inicie os Containers Docker
```bash
# Inicie todos os servi√ßos
docker-compose up -d
```

Aguarde alguns minutos para todos os servi√ßos iniciarem.

### 6Ô∏è‚É£ Verifique se tudo est√° rodando
```bash
docker-compose ps
```

---

## ‚ñ∂Ô∏è Como Executar
### 1Ô∏è‚É£ Acesse a Interface do Airflow
Abra seu navegador em: http://localhost:8080


### Credenciais padr√£o:
```text
Username: airflow
Password: airflow
```

2Ô∏è‚É£ Ative a DAG
1. Na interface do Airflow, localize a DAG astrotruck-etl
2. Clique no bot√£o de Acionar/Trigger para ativ√°-la
3. A DAG est√° configurada para executar a cada 1 hora

---

### üë∑ Autor
[Github](https://www.linkedin.com/in/juniiorsilvadev/) 